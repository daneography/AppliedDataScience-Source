{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: Part I - The Beautiful Soup Package\n",
    "\n",
    "```\n",
    "Prepared for CPSC4300/6300 Section 001 -- Applied Data Science\n",
    "Xizhou Feng\n",
    "Clemson University\n",
    "Fall 2020\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Many data science projects involve the task of retrieving data from multiple dats sources. Because web sites have been an important data sources, being able to effectively and quickly extracting necessary infomation available on the Internet is a must-have skill for today's data science practitioner.\n",
    "\n",
    "In this notebook, we learn how to use Python to scape data from web sites. We organize the note book into two parts:\n",
    "\n",
    "1. Learn the Beautiful Soup Package\n",
    "2. Extract the Clemson Tigers roster from ESPN's web site.\n",
    "\n",
    "After finishing this notebook, you should be able to scrape other websites as well. \n",
    "\n",
    "This notebook is compiled based on the *Beautiful Soup Documentation* (URL:   https://www.crummy.com/software/BeautifulSoup/bs4/doc/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Structure of Web Page\n",
    "\n",
    "Most web pages are written in HTML, which stands for Hyper Text Markup Language. HTML describes the structure of a Web page by putting a series of elements represented by tags into a text file. \n",
    "\n",
    "Browsers then use the HTML tags to render the contents of the page. Although browsers do not display these tags on the screen, you can use the \"Developer Tools\" provided by a modern browser to view the HTML source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Check the contents of a web page\n",
    "\n",
    "1. Open www.us.gov in a brwoser.\n",
    "2. Open the \"Develop Tools\" in a browser to examine the elements of the web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Document Object Model\n",
    "\n",
    "The HTML DOM (Document Object Model) abstracts a web page into a tree of objects. For example, the figure on the right represents the DOM tree of the HTML source on the left.\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://www.w3schools.com/js/pic_htmltree.gif\">\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>My Title</title>\n",
    "  </head>\n",
    "  \n",
    "  <body>\n",
    "    <a href=\"https://usa.gov\">My link</a>\n",
    "    <h1>My header</h1>\n",
    "  </body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this tree structure, we can find:\n",
    "\n",
    "+ A document consists of a set of nodes organized in a hierachical manner.\n",
    "+ There are at least four types of nodes: \n",
    "   + Document node: the root of the DOM tree.\n",
    "   + Element node: a block of text enclosed by a pair of tags, for example, ```<h1>My header</h1>```.\n",
    "   + Text node: a leaf node consisting of a block of text without tag.\n",
    "   + Attribute node: an attribute inside the openning tag, for example, ```href=\"https://usa.gov```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Beautiful Soup Library\n",
    "\n",
    "Beautiful Soup is a Python library for extracting data out of HTML and XML files. It provides idiomatic ways of navigating, searching, and modifying a DOM tree parsed from a web page. See: https://www.crummy.com/software/BeautifulSoup/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Beautiful Soup\n",
    "\n",
    "Here, we consider the following HTML text. First, we assign the text to a variable `html_doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>My Title</title>\n",
    "  </head>\n",
    "\n",
    "  <body>\n",
    "    <a href=\"https://usa.gov\">My link</a>\n",
    "    <h1>My header</h1>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import the `BeautifulSoup` class from the `bs4` package.\n",
    "\n",
    "### Review: Python module and package\n",
    "\n",
    "Python module is an organizational unit of Python code. Python modules have a namespace containing arbitrary Python objects. Python code in one module gains access to the code in another module by the process of importing it. \n",
    "\n",
    "Python has only one type of module object, and all modules are of this type. Considering the large number of modules, Python use the concept of packages to help organize modules and provide a naming hierarchy. You can think of packages as the directories on a file system and modules as files within directories, although packages and modules need not originate from the file system.\n",
    "\n",
    "All modules have a name. Subpackage names are separated from their parent package name by dots, akin to Python’s standard attribute access syntax. Thus you might have a module called sys and a package called email, which in turn has a subpackage called email.mime and a module within that subpackage called email.mime.text.\n",
    "\n",
    "The `import` statement is the most common way to import a module. Below are some examples:\n",
    "\n",
    "```\n",
    "import math                       # math imported and bounded locally\n",
    "import os.path                    # os.path imported and bounded locally\n",
    "import numpy as np                # numpy imported and bounded as np\n",
    "from bs4 import BeautifulSoup     # bs4 imported bs4.BeautifulSoup as BeautifulSoup\n",
    "```\n",
    "\n",
    "Executing the basic import statement involves in two steps:\n",
    "\n",
    "1. find a module, loading and initializing it if necessary\n",
    "1. define a name or names in the local namespace for the scope where the import statement occurs.\n",
    "\n",
    "\n",
    "The `from` form of the `import` statement involves a slightly more complex process:\n",
    "\n",
    "1. find the module specified in the from clause, loading and initializing it if necessary;\n",
    "1. for each of the identifiers specified in the import clauses:\n",
    "   1. check if the imported module has an attribute by that name\n",
    "   1. if not, attempt to import a submodule with that name and then check the imported module again for that attribute\n",
    "   1. if the attribute is not found, ImportError is raised.\n",
    "   1. otherwise, a reference to that value is stored in the local namespace, using the name in the as clause if it is present, otherwise using the attribute name\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `BeautifulSoup` is a class representing a parsed HTML or XML document. Internally, this class defines the basic interface called by the tree builders when converting an HTML/XML document into a data structure.\n",
    "\n",
    "In Python, every class use a constructor to initialize an object of its type. The function `__init__` defines the constructor for a class. \n",
    "\n",
    "## Tips: access Python documentation and source code\n",
    "\n",
    "You can use the `?` and `??` to access the documentation and source code of a Python module respectively.\n",
    "\n",
    "For example, `?BeautifulSoup` will show the documentation of the BeautifulSoup and `??BeautifulSoup` will show the corresponding sourec code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "?BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "??BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinds of Beautiful Soup Objects\n",
    "\n",
    "Beautiful Soup transforms a HTML document into a tree of Python objects. Normally, we deals with four kinds of objects when scraping a webpage using Beautiful Soup: \n",
    "+ `Tag`: corresponds to an XML or HTML tag in the original document.\n",
    "+ `NavigableString`: corresponds to a bit of text within a tag.\n",
    "+ `BeautifulSoup`: represents the document as a whole. \n",
    "+ `Comment`: a special type of NavigableString object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The BeautifulSoup Object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASCII_SPACES',\n",
       " 'DEFAULT_BUILDER_FEATURES',\n",
       " 'NO_PARSER_SPECIFIED_WARNING',\n",
       " 'ROOT_TAG_NAME',\n",
       " '__bool__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_all_strings',\n",
       " '_check_markup_is_url',\n",
       " '_decode_markup',\n",
       " '_feed',\n",
       " '_find_all',\n",
       " '_find_one',\n",
       " '_is_xml',\n",
       " '_lastRecursiveChild',\n",
       " '_last_descendant',\n",
       " '_linkage_fixer',\n",
       " '_most_recent_element',\n",
       " '_namespaces',\n",
       " '_popToTag',\n",
       " '_should_pretty_print',\n",
       " 'append',\n",
       " 'attrs',\n",
       " 'builder',\n",
       " 'can_be_empty_element',\n",
       " 'cdata_list_attributes',\n",
       " 'childGenerator',\n",
       " 'children',\n",
       " 'clear',\n",
       " 'contains_replacement_characters',\n",
       " 'contents',\n",
       " 'currentTag',\n",
       " 'current_data',\n",
       " 'declared_html_encoding',\n",
       " 'decode',\n",
       " 'decode_contents',\n",
       " 'decompose',\n",
       " 'decomposed',\n",
       " 'descendants',\n",
       " 'element_classes',\n",
       " 'encode',\n",
       " 'encode_contents',\n",
       " 'endData',\n",
       " 'extend',\n",
       " 'extract',\n",
       " 'fetchNextSiblings',\n",
       " 'fetchParents',\n",
       " 'fetchPrevious',\n",
       " 'fetchPreviousSiblings',\n",
       " 'find',\n",
       " 'findAll',\n",
       " 'findAllNext',\n",
       " 'findAllPrevious',\n",
       " 'findChild',\n",
       " 'findChildren',\n",
       " 'findNext',\n",
       " 'findNextSibling',\n",
       " 'findNextSiblings',\n",
       " 'findParent',\n",
       " 'findParents',\n",
       " 'findPrevious',\n",
       " 'findPreviousSibling',\n",
       " 'findPreviousSiblings',\n",
       " 'find_all',\n",
       " 'find_all_next',\n",
       " 'find_all_previous',\n",
       " 'find_next',\n",
       " 'find_next_sibling',\n",
       " 'find_next_siblings',\n",
       " 'find_parent',\n",
       " 'find_parents',\n",
       " 'find_previous',\n",
       " 'find_previous_sibling',\n",
       " 'find_previous_siblings',\n",
       " 'format_string',\n",
       " 'formatter_for_name',\n",
       " 'get',\n",
       " 'getText',\n",
       " 'get_attribute_list',\n",
       " 'get_text',\n",
       " 'handle_data',\n",
       " 'handle_endtag',\n",
       " 'handle_starttag',\n",
       " 'has_attr',\n",
       " 'has_key',\n",
       " 'hidden',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'insert_after',\n",
       " 'insert_before',\n",
       " 'isSelfClosing',\n",
       " 'is_empty_element',\n",
       " 'is_xml',\n",
       " 'known_xml',\n",
       " 'markup',\n",
       " 'name',\n",
       " 'namespace',\n",
       " 'new_string',\n",
       " 'new_tag',\n",
       " 'next',\n",
       " 'nextGenerator',\n",
       " 'nextSibling',\n",
       " 'nextSiblingGenerator',\n",
       " 'next_element',\n",
       " 'next_elements',\n",
       " 'next_sibling',\n",
       " 'next_siblings',\n",
       " 'object_was_parsed',\n",
       " 'original_encoding',\n",
       " 'parent',\n",
       " 'parentGenerator',\n",
       " 'parents',\n",
       " 'parse_only',\n",
       " 'parserClass',\n",
       " 'parser_class',\n",
       " 'popTag',\n",
       " 'prefix',\n",
       " 'preserve_whitespace_tag_stack',\n",
       " 'preserve_whitespace_tags',\n",
       " 'prettify',\n",
       " 'previous',\n",
       " 'previousGenerator',\n",
       " 'previousSibling',\n",
       " 'previousSiblingGenerator',\n",
       " 'previous_element',\n",
       " 'previous_elements',\n",
       " 'previous_sibling',\n",
       " 'previous_siblings',\n",
       " 'pushTag',\n",
       " 'recursiveChildGenerator',\n",
       " 'renderContents',\n",
       " 'replaceWith',\n",
       " 'replaceWithChildren',\n",
       " 'replace_with',\n",
       " 'replace_with_children',\n",
       " 'reset',\n",
       " 'select',\n",
       " 'select_one',\n",
       " 'setup',\n",
       " 'smooth',\n",
       " 'string',\n",
       " 'string_container',\n",
       " 'string_container_stack',\n",
       " 'strings',\n",
       " 'stripped_strings',\n",
       " 'tagStack',\n",
       " 'text',\n",
       " 'unwrap',\n",
       " 'wrap']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>My Title</title>\n",
       "</head>\n",
       "<body>\n",
       "<a href=\"https://usa.gov\">My link</a>\n",
       "<h1>My header</h1>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[document]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>My Title</title>\n",
       " </head>\n",
       " <body>\n",
       " <a href=\"https://usa.gov\">My link</a>\n",
       " <h1>My header</h1>\n",
       " </body>\n",
       " </html>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x7fa7ec1e72b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "html\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for child in soup.children:\n",
    "    print(child.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1>My header</h1>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>My header</h1>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Tag Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\n",
       "<title>My Title</title>\n",
       "</head>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'head'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x7fa7ec2bc100>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>My Title</title>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.find(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>My Title</title>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.find_all(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Attribute Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = soup.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://usa.gov\">My link</a>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = link.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'href': 'https://usa.gov'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = attrs['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://usa.gov'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Text Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My link\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "link = soup.find('a')\n",
    "text = link.get_text()\n",
    "print(text)\n",
    "print(type(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigate the tree\n",
    "\n",
    "### Going down\n",
    "\n",
    "#### Navigating using tag names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\n",
       "<title>My Title</title>\n",
       "</head>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>My Title</title>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://usa.gov\">My link</a>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://usa.gov\">My link</a>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigating using links from a node to its children.\n",
    "\n",
    "+ `.contents`: an attribute that provides a list of a tag’s childre.\n",
    "+ `.children`: an attribute that provides a generator to iterate over a tag’s children.\n",
    "+ `.descendants`: an attribute that allows iterating over all of a tag’s children, recursively: its direct children, the children of its direct children, and so on.\n",
    "+ `.string`: If a tag has only one child, and that child is a NavigableString, the child is made available as `.string`.\n",
    "+ `.strings`: a generator that returns more than one thing inside a tag.\n",
    "+ `.stripped_strings`: a generator that is similar to `strings` but will remove extra whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Up\n",
    "+ `.parent`: an attribute that returns an element’s parent.\n",
    "+ `.parents`: an attributes that iterates over all of an element’s parents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going sideways\n",
    "+ `.next_sibling`\n",
    "+ `.previous_sibling`\n",
    "+ `.next_siblings`\n",
    "+ `.previous_siblings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going back and forth\n",
    "\n",
    "+ `.next_element`\n",
    "+ `.previous_element`\n",
    "+ `.next_elements`\n",
    "+ `.previous_elements`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching the Tree\n",
    "\n",
    "Beautiful Soup defines several methods for searching the parse tree. Among these methods, the two most popular methods are:\n",
    "\n",
    "+ `find_all(name, attrs, recursive, string, limit, **kwargs)`\n",
    "   + `find_all()` returns the at most *limit* elements that matche a filter. \n",
    "+ `find(name, attrs, recursive, string, **kwargs)`\n",
    "   + `find()` returns the first elements that matches a filter.\n",
    "\n",
    "`find()` is equivalent to `find_all()` with argument `limit=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters\n",
    "\n",
    "You can pass in a filter to an argument like find_all() to include only the parts of the document which you are interested in. BeautifulSoup supports several kinds of filters which you can use them to filter based on a tag’s name, on its attributes, on the text of a string, or on some combination of these.\n",
    "\n",
    "+ A string: The simplest filter is a string. Pass a string to a search method and Beautiful Soup will perform a match against that exact string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://usa.gov\">My link</a>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ A regular expression: If you pass in a regular expression object, Beautiful Soup will filter against that regular expression using its `search()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>My Title</title>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for tag in soup.find_all(re.compile(\"^t\")):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ A list: If you pass in a list, Beautiful Soup will allow a string match against any item in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://usa.gov\">My link</a>\n",
      "<h1>My header</h1>\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all([\"a\", \"h1\"]):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ True: The value True matches everything it can. This code finds all the tags in the document, but none of the text strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "head\n",
      "title\n",
      "body\n",
      "a\n",
      "h1\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(True):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ A Function: You can also define a function that takes an element as its only argument and use it as a filter. The function should return True if the argument matches, and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_to_gov(tag):\n",
    "    if tag.name == 'a' and tag.has_attr('href') and tag.attrs['href'].endswith('.gov'):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://usa.gov\">My link</a>\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(link_to_gov):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_all\n",
    "\n",
    "`find_all(name, attrs, recursive, string, limit, **kwargs)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The name argument\n",
    "Passing in a value for name tells Beautiful Soup to only consider tags with certain names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>My Title</title>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The keyword argument\n",
    "Any argument that’s not recognized will be turned into a filter on one of a tag’s attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://usa.gov\">My link</a>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "soup.find_all(href=re.compile(\".gov$\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search by CSS class\n",
    "\n",
    "It’s very useful to search for a tag that has a certain CSS class. Because the name of the CSS attribute, “class”, is a reserved word in Python, using class as a keyword argument will give you a syntax error. As of Beautiful Soup 4.1.2, you can search by CSS class using the keyword argument class_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The string argument\n",
    "With string you can search for strings instead of tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My Title', 'My link', 'My header']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=re.compile(\"My\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The limit argument\n",
    "The limit argument tells Beautiful Soup to stop gathering results after it’s found a certain number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My Title']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=re.compile(\"My\"), limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The recursive argument\n",
    "If you call mytag.find_all(), Beautiful Soup will examine all the descendants of mytag: its children, its children’s children, and so on. If you only want Beautiful Soup to consider direct children, you can pass in recursive=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('title')\n",
    "soup.find_all('title', recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shortcut for find_all()\n",
    "If you treat the BeautifulSoup object or a Tag object as though it were a function, then it’s the same as calling find_all() on that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My Title']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\")\n",
    "soup(\"a\")\n",
    "soup.title.find_all(string=True)\n",
    "soup.title(string=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find\n",
    "Signature: find(name, attrs, recursive, string, **kwargs)\n",
    "\n",
    "find() returns a single result. It is equivalent to find_all() with argument limit=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://usa.gov\">My link</a>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find_all(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://usa.gov\">My link</a>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find(\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other find methods\n",
    "\n",
    "#### find_parents() and find_parent()\n",
    "\n",
    "+ `find_parents(name, attrs, string, limit, **kwargs)`\n",
    "+ `find_parent(name, attrs, string, **kwargs)`\n",
    "\n",
    "Remember that find_all() and find() work their way down the tree, looking at tag’s descendants. The above two methods do the opposite: they work their way up the tree, looking at a tag’s (or a string’s) parents.\n",
    "\n",
    "#### Find siblings\n",
    "+ `find_next_siblings(name, attrs, string, limit, **kwargs)`\n",
    "+ `find_next_sibling(name, attrs, string, **kwargs)`\n",
    "+ `find_previous_siblings(name, attrs, string, limit, **kwargs)`\n",
    "+ `find_previous_sibling(name, attrs, string, **kwargs)`\n",
    "\n",
    "#### find next and previous\n",
    "+ `find_all_next(name, attrs, string, limit, **kwargs)`\n",
    "+ `find_next(name, attrs, string, **kwargs)`\n",
    "+ `find_all_previous(name, attrs, string, limit, **kwargs)`\n",
    "+ `find_previous(name, attrs, string, **kwargs)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS selectors\n",
    "\n",
    "CSS (stands for Cascading Style Sheets) describes how HTML elements are to be displayed on screen, paper, or in other media. CSS saves a lot of work in web design as it can control the layout of multiple web pages all at once.\n",
    "\n",
    "In CSS, selectors are patterns used to select the element(s) you want to style. To know more about CSS and CSS selectors, you can read some tutorials provided at the W3Schools website (e.g., https://www.w3schools.com/cssref/css_selectors.asp).\n",
    "\n",
    "As of version 4.7.0, Beautiful Soup supports most CSS4 selectors via the SoupSieve project. BeautifulSoup has a .select() method which uses SoupSieve to run a CSS selector against a parsed document and return all the matching elements. Tag has a similar method which runs a CSS selector against the contents of a single tag.\n",
    "\n",
    "Generally speaking, you can use the `find`, `find_all`, and their derivatives to achieve all you want to get from CSS selectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"title\")\n",
    "soup.select(\"p:nth-of-type(3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find tags under other tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>My Title</title>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"body a\")\n",
    "soup.select(\"html head title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find tags directly under other tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-043b4f8f4e99>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-043b4f8f4e99>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    soup.select(\"head > title\") soup.select(\"body > a\") soup.select(\"p > a\") soup.select(\"p > #link1\")\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "soup.select(\"head > title\") soup.select(\"body > a\") soup.select(\"p > a\") soup.select(\"p > #link1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find the siblings of tags\n",
    "   + Find all siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"#link1 ~ .sister\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find first sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"#link1 + .sister\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find tags by CSS class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\".sister\")\n",
    "soup.select(\"[class~=sister]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find tags by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"#link1\")\n",
    "soup.select(\"a#link2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find tags that match any selector from a list of selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"#link1,#link2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Test for the existence of an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('a[href]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Find tags by attribute value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('a[href=\"http://example.com/elsie\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   + Starts with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('a[href^=\"http://example.com/\"]')\n",
    "   + Ends with\n",
    "soup.select('a[href$=\"tillie\"]')\n",
    "\n",
    "   + Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('a[href*=\".com/el\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('a[href*=\".com/el\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find only the first matching tag select_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select_one(\".sister\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "+ Pretty-printing\n",
    "The `prettify()` method will turn a Beautiful Soup parse tree into a nicely formatted Unicode string, with a separate line for each tag and each string.\n",
    "\n",
    "+ Non-pretty printing\n",
    "If you just want a string, with no fancy formatting, you can call `unicode()` or `str()` on a BeautifulSoup object, or a Tag.\n",
    "\n",
    "+ `get_text()`\n",
    "If you only want the text part of a document or tag, you can use the get_text() method. It returns all the text in a document or beneath a tag, as a single Unicode string."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
